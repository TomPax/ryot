{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Installation","text":"<p>Use the following docker-compose file:</p> <pre><code>services:\nryot-db:\nimage: postgres:16-alpine # at-least version 15 is required\nrestart: unless-stopped\ncontainer_name: ryot-db\nvolumes:\n- postgres_storage:/var/lib/postgresql/data\nenvironment:\n- TZ=Europe/Amsterdam\n- POSTGRES_DB=postgres\n- POSTGRES_USER=postgres\n- POSTGRES_PASSWORD=postgres\n\nryot:\nimage: ignisda/ryot:v8 # or ghcr.io/ignisda/ryot:v8\npull_policy: always\ncontainer_name: ryot\nrestart: unless-stopped\nports:\n- \"8000:8000\"\nenvironment:\n- TZ=Europe/Amsterdam\n- SERVER_ADMIN_ACCESS_TOKEN=28ebb3ae554fa9867ba0 # CHANGE THIS\n- DATABASE_URL=postgres://postgres:postgres@ryot-db:5432/postgres\n\nvolumes:\npostgres_storage:\n</code></pre> <p>If you would like to run the pro version, please check below. To see the features of the pro version, check the features page.</p>"},{"location":"index.html#upgrading-to-pro","title":"Upgrading to Pro","text":"<p>To upgrade to the pro version, you need to provide a <code>SERVER_PRO_KEY</code> environment variable. You can get a key by purchasing it from the website.</p> <p>Once you have the key, you can set it in the <code>docker-compose.yml</code> file:</p> <pre><code>  ryot:\n    environment:\n+      - SERVER_PRO_KEY=&lt;pro_key_issued_to_you&gt;\n</code></pre> <p>If the key is invalid or your subscription has expired, the server will automatically start with the community version. Since the two versions are compatible, you can switch between them by simply fixing the key and restarting the server.</p>"},{"location":"index.html#releases","title":"Releases","text":"<p>Each version of Ryot is released as docker images. For example, if the latest tag is <code>v5.2.1</code>, then the docker image will be tagged as <code>v5.2.1</code>, <code>v5.2</code>, <code>v5</code>, <code>latest</code> and <code>sha-e145f71</code>. The images will be made available on Docker Hub and GitHub Container Registry. Ryot is released on a (loosely) weekly basis.</p> <p>If you prefer to live on the edge, you can use the <code>develop</code> docker tag which is released when changes are merged into the <code>main</code> branch. Please note that this tag often has major bugs and results in data loss. Only use this tag if you know what you are doing.</p>"},{"location":"index.html#telemetry","title":"Telemetry","text":"<p>Ryot collects anonymous usage data to help me prioritize features. It uses a self-hosted Umami instance to collect this data. In addition to page views, a few events are also tracked and you can find them in the source code.</p> <p>You can opt out of this by setting a configuration parameter as described here.</p>"},{"location":"configuration.html","title":"Configuration","text":"<p>You can specify configuration options via environment variables. Each option is documented below with what it does and a default (if any).</p> <p>Ryot serves the final configuration loaded at the <code>/backend/config</code> endpoint as JSON (example). Sensitive variables are redacted.</p>"},{"location":"configuration.html#important-parameters","title":"Important parameters","text":"Environment variable Description <code>PORT</code> The port to listen on. Defaults to <code>8000</code>. <code>TZ</code> Timezone to be used for cron jobs. Accepts values according to the IANA database. Defaults to <code>GMT</code>. <code>DISABLE_TELEMETRY</code> Disables telemetry collection using Umami. Defaults to <code>false</code>. <code>DATABASE_URL</code> The Postgres database connection string. <code>VIDEO_GAMES_TWITCH_CLIENT_ID</code> The client ID issued by Twitch. Required to enable video games tracking. More information <code>VIDEO_GAMES_TWITCH_CLIENT_SECRET</code> The client secret issued by Twitch. Required to enable video games tracking."},{"location":"configuration.html#health-endpoint","title":"Health endpoint","text":"<p>The <code>/health</code> endpoint can be used for checking service healthiness. More information here.</p>"},{"location":"configuration.html#all-parameters","title":"All parameters","text":"<p>Please refer to the <code>@envvar</code> annotations to know which environment variable to use for a given parameter.</p> <pre><code># Settings related to anime and manga.\nanime_and_manga:\n# Settings related to Anilist.\nanilist:\n# The preferred language for media from this source.\n# @envvar ANIME_AND_MANGA_ANILIST_PREFERRED_LANGUAGE\npreferred_language: \"native\"\n\n# Settings related to MAL.\nmal:\n# The client ID to be used for the MAL API.\n# @envvar ANIME_AND_MANGA_MAL_CLIENT_ID\nclient_id: \"\"\n\n# Settings related to MangaUpdates.\nmanga_updates: {}\n\n# Settings related to audio books.\naudio_books:\n# Settings related to Audible.\naudible:\n# Settings related to locale for making requests Audible.\n# @envvar AUDIO_BOOKS_AUDIBLE_LOCALE\nlocale: \"us\"\n\n# Settings related to books.\nbooks:\n# Settings related to Google Books.\ngoogle_books:\n# The API key to be used for the Google Books API.\n# @envvar BOOKS_GOOGLE_BOOKS_API_KEY\napi_key: \"\"\n\n# Whether to pass the raw query string to the search API.\n# @envvar BOOKS_GOOGLE_BOOKS_PASS_RAW_QUERY\npass_raw_query: false\n\n# Settings related to Hardcover.\nhardcover:\n# The API key to be used.\n# @envvar BOOKS_HARDCOVER_API_KEY\napi_key: \"\"\n\n# Settings related to Openlibrary.\nopenlibrary:\n# The image sizes to fetch from Openlibrary.\n# @envvar BOOKS_OPENLIBRARY_COVER_IMAGE_SIZE\ncover_image_size: \"M\"\n\n# The database related settings.\ndatabase:\n# The Postgres database connection string.\n# Format described in https://www.sea-ql.org/SeaORM/docs/install-and-config/connection/#postgres.\n# @envvar DATABASE_URL\nurl: \"\"\n\n# Whether to disable telemetry.\n# @envvar DISABLE_TELEMETRY\ndisable_telemetry: false\n\n# Settings related to exercises.\nexercise: {}\n\n# Settings related to file storage.\nfile_storage:\n# The access key ID for the S3 compatible file storage. **Required** to\n# enable file storage.\n# @envvar FILE_STORAGE_S3_ACCESS_KEY_ID\ns3_access_key_id: \"\"\n\n# The name of the S3 compatible bucket. **Required** to enable file storage.\n# @envvar FILE_STORAGE_S3_BUCKET_NAME\ns3_bucket_name: \"\"\n\n# The region for the S3 compatible file storage.\n# @envvar FILE_STORAGE_S3_REGION\ns3_region: \"us-east-1\"\n\n# The secret access key for the S3 compatible file storage. **Required**\n# to enable file storage.\n# @envvar FILE_STORAGE_S3_SECRET_ACCESS_KEY\ns3_secret_access_key: \"\"\n\n# The URL for the S3 compatible file storage.\n# @envvar FILE_STORAGE_S3_URL\ns3_url: \"\"\n\n# Settings related to frontend storage.\nfrontend:\n# A message to be displayed on the dashboard.\n# @envvar FRONTEND_DASHBOARD_MESSAGE\ndashboard_message: \"\"\n\n# The button label for OIDC authentication.\n# @envvar FRONTEND_OIDC_BUTTON_LABEL\noidc_button_label: \"Continue with OpenID Connect\"\n\n# Settings related to Umami analytics.\numami:\n# @envvar FRONTEND_UMAMI_DOMAINS\ndomains: \"\"\n\n# For example: https://umami.is/script.js.\n# @envvar FRONTEND_UMAMI_SCRIPT_URL\nscript_url: \"\"\n\n# @envvar FRONTEND_UMAMI_WEBSITE_ID\nwebsite_id: \"\"\n\n# Used as the base URL when generating item links for the frontend.\n# @envvar FRONTEND_URL\nurl: \"https://app.ryot.io\"\n\n# Settings related to external integrations.\nintegration:\n# Sync data from push and yank based integrations every `n` minutes.\n# @envvar INTEGRATION_SYNC_EVERY_MINUTES\nsync_every_minutes: 5\n\n# Settings related to media.\nmedia:\n# Number of days after which a media should be removed from the Monitoring collection.\n# @envvar MEDIA_MONITORING_REMOVE_AFTER_DAYS\nmonitoring_remove_after_days: 30\n\n# Settings related to movies and shows.\nmovies_and_shows:\n# Settings related to TMDB.\ntmdb:\n# The access token for the TMDB API.\n# @envvar MOVIES_AND_SHOWS_TMDB_ACCESS_TOKEN\naccess_token: \"\"\n\n# The locale to use for making requests to TMDB API.\n# @envvar MOVIES_AND_SHOWS_TMDB_LOCALE\nlocale: \"en\"\n\n# Settings related to music.\nmusic: {}\n\n# Settings related to podcasts.\npodcasts:\n# Settings related to iTunes.\nitunes:\n# The locale to use for making requests to iTunes API.\n# @envvar PODCASTS_ITUNES_LOCALE\nlocale: \"en_us\"\n\n# Settings related to Listennotes.\nlistennotes:\n# The access token for the Listennotes API.\n# @envvar PODCASTS_LISTENNOTES_API_TOKEN\napi_token: \"\"\n\n# Settings related to server.\nserver:\n# An access token that can be used for admin operations.\n# @envvar SERVER_ADMIN_ACCESS_TOKEN\nadmin_access_token: \"\"\n\n# An array of URLs for CORS.\n# @envvar SERVER_CORS_ORIGINS\ncors_origins: []\n\n# Disable all background jobs.\n# @envvar SERVER_DISABLE_BACKGROUND_JOBS\ndisable_background_jobs: false\n\n# Whether the graphql playground will be enabled.\n# @envvar SERVER_GRAPHQL_PLAYGROUND_ENABLED\ngraphql_playground_enabled: true\n\n# Whether this is a demo instance.\n# @envvar SERVER_IS_DEMO_INSTANCE\nis_demo_instance: false\n\n# The maximum file size in MB for user uploads.\n# @envvar SERVER_MAX_FILE_SIZE_MB\nmax_file_size_mb: 70\n\n# The OIDC related settings.\noidc:\n# @envvar SERVER_OIDC_CLIENT_ID\nclient_id: \"\"\n\n# @envvar SERVER_OIDC_CLIENT_SECRET\nclient_secret: \"\"\n\n# @envvar SERVER_OIDC_ISSUER_URL\nissuer_url: \"\"\n\n# The pro key assigned to the user.\n# @envvar SERVER_PRO_KEY\npro_key: \"\"\n\n# The hours in which a media can be marked as seen again for a user. This\n# is used so that the same media can not be used marked as started when\n# it has been already marked as seen in the last `n` hours.\n# @envvar SERVER_PROGRESS_UPDATE_THRESHOLD\nprogress_update_threshold: 2\n\n# Number of seconds to sleep before starting the server.\n# @envvar SERVER_SLEEP_BEFORE_STARTUP_SECONDS\nsleep_before_startup_seconds: 0\n\n# The mailer related settings.\nsmtp:\n# @envvar SERVER_SMTP_MAILBOX\nmailbox: \"Ryot &lt;no-reply@mailer.io&gt;\"\n\n# @envvar SERVER_SMTP_PASSWORD\npassword: \"\"\n\n# @envvar SERVER_SMTP_SERVER\nserver: \"\"\n\n# @envvar SERVER_SMTP_USER\nuser: \"\"\n\n# Settings related to users.\nusers:\n# Whether new users will be allowed to sign up to this instance.\n# @envvar USERS_ALLOW_REGISTRATION\nallow_registration: true\n\n# Whether to disable local user authentication completely.\n# @envvar USERS_DISABLE_LOCAL_AUTH\ndisable_local_auth: false\n\n# The secret used for generating JWT tokens.\n# @envvar USERS_JWT_SECRET\njwt_secret: \"\"\n\n# The number of days till login authentication token is valid.\n# @envvar USERS_TOKEN_VALID_FOR_DAYS\ntoken_valid_for_days: 90\n\n# Settings related to video games.\nvideo_games:\n# Settings related to IGDB.\nigdb:\n# The image sizes to fetch from IGDB.\n# @envvar VIDEO_GAMES_IGDB_IMAGE_SIZE\nimage_size: \"t_original\"\n\n# Settings related to Twitch.\ntwitch:\n# The client ID issues by Twitch. **Required** to enable video games\n# tracking. [More information](/docs/guides/video-games.md).\n# @envvar VIDEO_GAMES_TWITCH_CLIENT_ID\nclient_id: \"\"\n\n# The client secret issued by Twitch. **Required** to enable video games\n# tracking.\n# @envvar VIDEO_GAMES_TWITCH_CLIENT_SECRET\nclient_secret: \"\"\n\n# Settings related to visual novels.\nvisual_novels: {}\n</code></pre>"},{"location":"contributing.html","title":"Contributing","text":"<ul> <li>Install Rust, Moon and   Caddy (&gt;= 2.7).</li> <li>Make sure you have PostgreSQL installed and running. I prefer using Docker e.g. <code>docker run -e POSTGRES_PASSWORD=postgres -e POSTGRES_USER=postgres -e POSTGRES_DB=postgres -p 5432:5432 postgres:16-alpine</code></li> <li>Create the following environment file in the root of the repository:</li> </ul> .env<pre><code>DATABASE_URL=postgres://postgres:postgres@localhost:5432/postgres\nDEFAULT_TMDB_ACCESS_TOKEN=your-tmdb-access-token\nDEFAULT_MAL_CLIENT_ID=your-mal-client-id\nTRAKT_CLIENT_ID=your-trakt-client-id\nUNKEY_API_ID=dummy-api-id\nAPP_VERSION=v5.2.1\n</code></pre> <ul> <li>Run the following commands in separate terminals:</li> </ul> <pre><code>cargo run\nmoon run frontend:dev\ncaddy run --config 'ci/Caddyfile'\n</code></pre> <ul> <li>The frontend will be available at <code>http://localhost:8000</code>.</li> </ul> <p>In development, both servers are started independently running on <code>:3000</code> and <code>:5000</code> respectively and reverse proxied at <code>:8000</code>.</p> <p>If you want to work on exporting, then you need to also have Minio installed and running on <code>localhost:9000</code>.</p>"},{"location":"deployment.html","title":"Deployment","text":"<p>The easiest way to deploy Ryot is using the docker compose. Here is a non-exhaustive set of guides to deploy Ryot to alternative platforms.</p>"},{"location":"deployment.html#railway","title":"Railway","text":"<ol> <li>Click on \"+ New Project\" on your dashboard and select \"Empty project\".</li> <li>Once the project is created click on \"+ New\" and select \"Database\" and then   \"Add PostgreSQL\".</li> <li>Click on \"+ New\" again and select \"Docker Image\". Type <code>ignisda/ryot</code> and hit Enter.</li> <li>Click on the newly created service and go to the \"Variables\" section. Click on   \"New Variable\" and then \"Add Reference\". Click on \"Add\".</li> <li>Go to the \"Settings\" tab and then click on \"Generate Domain\".</li> <li>Optionally, you can set the health-check   path to <code>/health</code>.</li> </ol>"},{"location":"deployment.html#dokku","title":"Dokku","text":"<p>This is a script that automatically sets up a Ryot server using the docker image uploaded to Ghcr and creates a Dokku app. The script assumes you have a global domain set-up (i.e. the file <code>/home/dokku/VHOST</code> exists). It needs to be run with <code>sudo</code> privileges.</p> <p>Re-running it updates the running server to the latest version.</p> <pre><code>#!/usr/bin/env bash\n\nset -euo pipefail\n\nif [ \"$EUID\" -ne 0 ]\nthen echo \"Please run as root\"\nexit\nfi\n\nIMAGE_NAME=\"ignisda/ryot\"\nAPPNAME=\"\"\n\nread -rp \"Enter the name of the app: \" APPNAME\n\n# check if app name is empty\nif [ -z \"$APPNAME\" ]; then\necho \"App name empty. Using default name: ryot\"\nAPPNAME=\"ryot\"\nfi\n\n# pull the latest image\ndocker rmi -f \"$IMAGE_NAME\" || true\ndocker pull \"$IMAGE_NAME:latest\"\nimage_sha=\"$(docker inspect --format=\"{{index .RepoDigests 0}}\" $IMAGE_NAME)\"\necho \"Calculated image sha: $image_sha\"\n\nif dokku apps:exists $APPNAME; then\ndokku git:from-image $APPNAME $image_sha || echo \"Already on latest\"\nexit 0\nfi\n\ndokku apps:create \"$APPNAME\"\ndokku postgres:create \"$APPNAME-service\"\ndokku postgres:link \"$APPNAME-service\" \"$APPNAME\"\n\n# check if required dokku plugin exists\nif ! dokku plugin:list | grep letsencrypt; then\ndokku plugin:install https://github.com/dokku/dokku-letsencrypt.git\nfi\n\ndokku domains:add $APPNAME $APPNAME.\"$(cat /home/dokku/VHOST)\"\ndokku letsencrypt:enable \"$APPNAME\"\ndokku git:from-image \"$APPNAME\" \"$image_sha\"\n</code></pre>"},{"location":"deployment.html#fly","title":"Fly","text":"<p>The demo Ryot instance is deployed to Fly. The following steps are required to deploy to Fly.</p> <ol> <li> <p>Create a new postgres database for Ryot.    <pre><code>flyctl postgres create ryot-db\n</code></pre></p> </li> <li> <p>Copy the <code>fly.toml</code> file from this    repository to your own repository. You WILL have to change the <code>app</code> key to    a unique name. Deploy it using the below command.    <pre><code>flyctl launch\n</code></pre></p> </li> <li> <p>Connect the database.    <pre><code>fly postgres attach --app ryot ryot-db\n</code></pre></p> </li> <li> <p>Optionally you can configure the instance using <code>fly secrets set</code>.    <pre><code>fly secrets set FILE_STORAGE_S3_URL='https://play.min.io:9000'\n</code></pre></p> </li> </ol>"},{"location":"deployment.html#cosmos","title":"Cosmos","text":"<p>You can install <code>ryot</code> from the Cosmos marketplace using this link: Install Ryot or by searching for <code>Ryot</code> in the marketplace.</p> <p>Review the installation summary and click install to proceed. The database and credentials will be automatically created for you, but make sure you are happy with the URL chosen.</p> <p>The instance will be available under your newly created URL via HTTPS if it is enabled. You can then proceed with creating your first user via the web interface's registration page.</p>"},{"location":"importing.html","title":"Importing","text":"<p>Importing is meant to be a one-time operation. They are irreversible, i.e., importing from the same source twice will create duplicates. I recommend you to make a database backup before starting an import.</p> <p>An import can fail at various steps. Ryot creates a report when an import completes/fails. You can see the reports under \"Import History\" of the imports page.</p>"},{"location":"importing.html#notes","title":"Notes","text":"<ul> <li>Imports are very difficult to have 100% success rate. Though we try our best,   you might have to manually import some data from your previous provider.</li> <li>Imports might take a long time since Ryot needs to fetch all metadata from the sources   before it can start importing progress. Estimated finish time is displayed in the UI.</li> <li>I recommend turning on debug logging for the duration of the import using the   <code>RUST_LOG=ryot=debug</code> environment variable. This will help you help you see import   progress in the docker logs.</li> </ul>"},{"location":"importing.html#jellyfin","title":"Jellyfin","text":"<p>You can import your watched movies and shows from Jellyfin.</p> <p>Info</p> <p>This will only import media that are already finished. Setup an   integration if you want to import media in progress.</p> <p>Enter the correct details in the input. The username you enter should be of the account whose data you want to import.</p>"},{"location":"importing.html#plex","title":"Plex","text":"<p>You can import your watched movies and shows from Plex.</p> <p>Info</p> <p>This will only import media that are already finished. Setup an   integration if you want to import media in progress.</p> <ol> <li>Obtain a <code>Plex-Token</code> as described    here.</li> <li>Enter the correct details in the inputs.</li> </ol>"},{"location":"importing.html#trakt","title":"Trakt","text":"<p>All movies and shows can be imported from Trakt along with their ratings, history, comments and lists. A few points to note.</p> <ul> <li>It is necessary to set your account's privacy to public during the   duration of the import.</li> <li>Items that have been \"check(ed) in\" will not be imported.</li> </ul> <ol> <li>Login to your Trakt account and go to the settings page.</li> <li>If your account is set to private, uncheck the box next to it. You can revert   this change once the import is complete.</li> <li>If you have any lists that are private, you need to change them to public.   Otherwise they will not be imported.</li> <li>Find your profile slug. This is usually your username. You can find it by   going to your profile page, and checking the URL.</li> <li>Enter this username in the input.</li> </ol>"},{"location":"importing.html#audiobookshelf","title":"Audiobookshelf","text":"<p>The Audiobookshelf importer supports importing all media that have a valid Audible ID or ITunes ID or ISBN.</p> <p>Info</p> <ul> <li>This will only import media that are already finished. Setup an   integration if you want to import media in progress.</li> <li>If you have enabled the option to auto delete podcast episodes, you'll have to   manually mark them as completed.</li> </ul> <ol> <li>Obtain an API token as described in the Audiobookshelf   authentication docs.</li> <li>Enter the correct details in the input.</li> </ol>"},{"location":"importing.html#goodreads","title":"Goodreads","text":"<p>Ryot translates Goodreads shelves in the following manner:</p> <ul> <li>Want To Read -&gt; Watchlist</li> </ul> <ol> <li>Login to your Goodreads account and go to the \"My Books\" section.</li> <li>Click on \"Import and export\" on the left sidebar.</li> <li>Click on \"Export Library\" and download the CSV file.</li> <li>Upload this file in the input.</li> </ol>"},{"location":"importing.html#mediatracker","title":"MediaTracker","text":"<p>You can import from MediaTracker, with the following caveats:</p> <ul> <li>Items that are in progress are always imported with 100% progress. They are   added to the \"In Progress\" collection so you can manually fix their progress   if needed.</li> </ul> <ol> <li>Login to your MediaTracker account and click on your name on the top right.</li> <li>Click on the \"Application tokens\" section.</li> <li>Enter a name and click on \"Add token\".</li> <li>Copy the token that was just generated.</li> <li>Enter the details in the inputs.</li> </ol>"},{"location":"importing.html#generic-json","title":"Generic Json","text":"<p>The \"Generic Json\" can be used to import all possible data from a generic JSON file. The format of the JSON file should be <code>CompleteExport</code> as described in the exporting documentation.</p> <p>You can use this to export all your data from one Ryot instance and import it into another, or from a source that is not supported by Ryot.</p>"},{"location":"importing.html#movary","title":"Movary","text":"<p>The Watchlist and all movies can be imported from Movary along with ratings, history, and comments.</p> <ol> <li>Login to your Movary account and go to the settings page. Go to \"Personal data\"   under the \"Account\" section.</li> <li>Export \"history.csv\", \"watchlist.csv\" and \"ratings.csv\".</li> <li>Upload these files in the input.</li> </ol>"},{"location":"importing.html#myanimelist","title":"MyAnimeList","text":"<p>Manga and Anime can be imported from MyAnimeList along with ratings, history and progress.</p> <ol> <li>Login to your MyAnimeList account and go to   exports.</li> <li>Export your anime and manga history.</li> <li>Upload these files in the input.</li> </ol>"},{"location":"importing.html#anilist","title":"Anilist","text":"<p>Manga and anime can be imported from Anilist along with ratings, history, favorites and custom lists.</p> <ol> <li>Login to your Anilist account and go to your account   settings.</li> <li>Scroll down to the \"GDPR Data Download\" section and click on \"Download\".</li> <li>Upload the JSON file in the input.</li> </ol>"},{"location":"importing.html#storygraph","title":"StoryGraph","text":"<p>Imports from StoryGraph work using ISBN. All books in your export that have an ISBN attached to them will be imported. Ryot translates \"Read Status\" in the following manner:</p> <ul> <li>to-read -&gt; Watchlist</li> </ul> <ol> <li>Login to your account and click on your profile and go to the \"Manage Account\"   page.</li> <li>Scroll to the bottom and click on \"Export StoryGraph Library\" and then   \"Generate export\".</li> <li>Once the export is done, you will receive an email. refresh the page above and   download the CSV file.</li> <li>Optionally, you can edit the CSV file and manually add the missing ISBN.</li> <li>Upload this file in the input.</li> </ol>"},{"location":"importing.html#strong-app","title":"Strong App","text":"<p>You can import your completed workouts from Strong app. If an exercise does not exist in your instance, it will be created. You can later use the \"Edit Exercise\" or \"Merge Exercise\" actions to map the exercise to an existing one.</p> <ol> <li>Login to your Strong account on the app and go to the \"Settings\" page.</li> <li>Scroll down to the \"General\" section and click on \"Export data\".</li> <li>Upload the csv file in the input.</li> </ol>"},{"location":"importing.html#hevy","title":"Hevy","text":"<p>You can import your workouts from Hevy. Exercises will be created using the same strategy as the Strong app importer.</p> <ol> <li>Login to your Hevy account on the app and go to the \"Profile\" page.</li> <li>Click on the cog icon on the top right and select \"Export &amp; Import Data\" under   \"Preferences\".</li> <li>Click on \"Export\" and then click on the button that says \"Export Workouts\".</li> <li>Upload the csv file in the input.</li> </ol>"},{"location":"importing.html#imdb","title":"IMDb","text":"<p>You can import your watchlist from IMDb. They will be added to the \"Watchlist\" collection.</p> <ol> <li>Go to your account and select your watchlist.</li> <li>Go the bottom and click on the \"Export this list\" button.</li> <li>Upload the csv file in the input.</li> </ol>"},{"location":"importing.html#igdb","title":"IGDb","text":"<p>You can import your lists from IGDb. Each list has to be imported separately. A few points to note:</p> <ul> <li>Importing into the \"In Progress\" collection will set 5% progress for the items.</li> <li>Importing into the \"Completed\" collection will set 100% progress for the items.</li> <li>Import into any other collection will just add the items to the collection.</li> </ul> <ol> <li>Login to your account and go to your profile. The default activity lists can be exported   from  here. Click on the list you want to export and download it as CSV.</li> <li>For your custom lists, please visit the \"My Lists\" page.</li> <li>Upload the CSV file and choose the collection you want to import into.</li> </ol>"},{"location":"importing.html#tv-time","title":"TV Time","text":"<p>Warning</p> <p>This is a community maintained integration.</p> <p>All shows can be imported from TvTime at the moment using an external tool. You can find all the necessary steps here.</p>"},{"location":"importing.html#open-scale","title":"Open Scale","text":"<p>You can import your measurements from Open Scale app.</p> <p>This can be done by clicking on the three dots on the top right corner of the app, and then clicking on \"Export\". This will save a CSV file to your file system. Upload this file in the input.</p>"},{"location":"integrations.html","title":"Integrations","text":"<p>Integrations can be used to continuously update your media progress or inform external services about changes. They can be of following types:</p> <ul> <li>Sink: An external client publishes progress updates to the Ryot server.</li> <li>Yank: Progress data is downloaded from an externally running server at a periodic   interval.</li> <li>Push: Ryot sends data to an external service when an event occurs.</li> </ul> <p>If an integration fails more than 5 times in a row, it will be automatically disabled.</p>"},{"location":"integrations.html#sink-integrations","title":"Sink integrations","text":"<p>These work via webhooks wherein an external service can inform Ryot about a change. All webhook URLs follow this format:</p> <pre><code>https://&lt;instance_url&gt;/backend/_i/&lt;slug&gt;\nhttps://app.ryot.io/backend/_i/int_a6cGGXEq6KOI # example\n</code></pre> <p>Warning</p> <p>Keep your webhook urls private to prevent abuse.</p>"},{"location":"integrations.html#jellyfin","title":"Jellyfin","text":"<p>Automatically add new Jellyin movie and show plays to Ryot. It will work for all the media that have a valid TMDb ID attached to their metadata.</p> <p>Info</p> <p>Requires the unofficial webhook plugin to be installed and active in Jellyfin.</p> <ol> <li>Generate a slug in the integration settings page. Copy the newly generated    webhook Url.</li> <li>In the Jellyfin webhook plugin settings, add a new webhook using the    following settings:<ul> <li>Webhook Url =&gt; <code>&lt;paste_url_copied&gt;</code></li> <li>Payload format =&gt; <code>Default</code></li> <li>Listen to events only for =&gt; Choose your user</li> <li>Events =&gt; <code>Play</code>, <code>Pause</code>, <code>Resume</code>, <code>Stop</code> and <code>Progress</code></li> </ul> </li> </ol>"},{"location":"integrations.html#emby","title":"Emby","text":"<p>Automatically add new Emby movie and show plays to Ryot. It will work for all the media that have a valid TMDb ID attached to their metadata.</p> <ol> <li>Generate a slug in the integration settings page. Copy the newly generated    webhook Url.</li> <li>In the Emby notification settings page, add a new notification using the    Webhooks option:<ul> <li>Name =&gt; <code>ryot</code></li> <li>Url =&gt; <code>&lt;paste_url_copied&gt;</code></li> <li>Request Content Type =&gt; <code>application/json</code></li> <li>Events =&gt; <code>Play</code>, <code>Pause</code>, <code>Resume</code>, <code>Stop</code> and <code>Progress</code></li> <li>Limit user events to =&gt; Choose your user</li> </ul> </li> </ol> <p>Warning</p> <p>Since Emby does not send the expected TMDb ID for shows, progress will only be synced if you already have the show in the Ryot database. To do this, simply add the show to your watchlist.</p>"},{"location":"integrations.html#plex-sink","title":"Plex Sink","text":"<p>Info</p> <p>This will only import media that are in progress. Perform an   import if you want to import media that are finished.</p> <p>Automatically add Plex show and movie plays to Ryot. It will work for all the media that have a valid TMDb ID attached to their metadata.</p> <ol> <li>Generate a slug in the integration settings page using the following settings:<ul> <li>Username =&gt; Your Plex <code>Fullname</code>. If you have no <code>Fullname</code> specified in Plex,    fallback to your Plex <code>Username</code>. This will be used to filter webhooks for the    specified Plex account only.</li> </ul> </li> <li>In your Plex Webhooks settings, add a new webhook using the following settings:<ul> <li>Webhook Url =&gt; <code>&lt;paste_url_copied&gt;</code></li> </ul> </li> </ol> <p>Warning</p> <p>Since Plex does not send the expected TMDb ID for shows, progress will only be synced if you already have the show in the Ryot database. To do this, simply add the show to your watchlist.</p>"},{"location":"integrations.html#kodi","title":"Kodi","text":"<p>The Kodi integration allows syncing the current movie or TV show you are watching. It will work for all the media that have a valid TMDb ID attached to their metadata.</p> <ol> <li>Generate a slug in the integration settings page. Copy the newly generated    webhook Url.</li> <li>Download the addon from github releases.    The file will have a name of <code>script.ryot.zip</code>.</li> <li>Install    the zipped addon to your Kodi instance. Once installed, it will be visible under    the \"Services\" sub category named \"Ryot\".</li> <li>Click on \"Configure\" to fill in the correct details.</li> </ol>"},{"location":"integrations.html#generic-json","title":"Generic Json","text":"<p>The \"Generic Json\" can be used to import all possible data using a generic JSON data format. The format of the JSON file should be <code>CompleteExport</code> as described in the exporting documentation.</p> <p>You can use this to build integrations with other services that Ryot does not support natively.</p>"},{"location":"integrations.html#yank-integrations","title":"Yank integrations","text":"<p>You can configure the interval at which the data is fetched from the external source using the <code>INTEGRATION_SYNC_EVERY_MINUTES</code> environment variable. Defaults to <code>5</code>.</p> <p>If you have enabled the <code>Sync to owned collection</code> option, the integration will also run at night to add all media in your instance to your \"Owned\" collection.</p>"},{"location":"integrations.html#audiobookshelf","title":"Audiobookshelf","text":"<p>Info</p> <p>This will only import media that are in progress. Perform an   import if you want to import media that are finished.</p> <p>The Audiobookshelf integration can sync all media if they have a valid provider ID (Audible, ITunes or ISBN).</p> <ol> <li>Obtain an API token as described in the Audiobookshelf    authentication docs.</li> <li>Go to your Ryot integrations settings and add the correct details as described in the    yank section.</li> </ol>"},{"location":"integrations.html#komga","title":"Komga","text":"<p>The Komga integration can sync all media if they have a valid metadata provider. If you use Komf or some similar metadata provider these urls will be populated automatically. If you don't, you will either need to manually add the manga to your collection or you can perform the following steps.</p> <ol> <li>Navigate to the manga and open the Edit tab</li> <li>Navigate to the Links tab</li> <li>Create a link named <code>AniList</code> or <code>MyAnimeList</code> providing the respective url (not    case-sensitive)</li> <li>On Ryot, create an integration and select Komga as the source</li> <li>Provide your Base URL. It should look something like this <code>https://komga.acme.com</code> or    <code>http://127.0.0.1:25600</code></li> <li>Provide your Username and Password.</li> <li>Provide your preferred metadata provider. Ryot will attempt the others if the preferred    is unavailable and will fallback to title search otherwise.</li> </ol>"},{"location":"integrations.html#plex-yank","title":"Plex Yank","text":"<p>This integration will add all media in your libraries to the \"Owned\" collection. If you want to sync media progress, then take a look at the Plex Sink integration.</p> <ol> <li>Get the Plex token. If you want to import data for an admin account, then you need a    device    token.    Otherwise, a current user    token    is sufficient.</li> <li>Go to your Ryot integration settings and fill in the details.</li> </ol>"},{"location":"integrations.html#youtube-music","title":"Youtube Music","text":"<p>  [Pro Version | ryot.io]  </p> <p>The Youtube Music integration syncs all music that you have listened to \"Today\". Since Youtube Music does not have an official API, this integration is prone to breakage and needs some roundabout steps to setup.</p> <ol> <li>Install the Cookie Editor extension in your browser. Make    sure you allow the extension to work on incognito windows.</li> <li>Open a new incognito window in your browser and login to Youtube Music.</li> <li>Once logged in, open the extension and export the cookies as \"Header String\". After    copying them, close the incognito browser immediately so that they are not invalidated.   </li> <li>Paste the exported cookies in the input.</li> </ol>"},{"location":"integrations.html#push-integrations","title":"Push integrations","text":"<p>You can enable the following push integrations:</p>"},{"location":"integrations.html#radarr","title":"Radarr","text":"<p>Events: <code>Item added to collection</code></p> <ol> <li>Obtain your Radarr API key by going to the Radarr general settings page.</li> <li>Fill the inputs in the integration settings page with the correct details.</li> </ol>"},{"location":"integrations.html#sonarr","title":"Sonarr","text":"<p>Events: <code>Item added to collection</code></p> <ol> <li>Obtain your Sonarr API key by going to the Sonarr general settings page.</li> <li>Fill the inputs in the integration settings page with the correct details.</li> </ol>"},{"location":"integrations.html#jellyfin_1","title":"Jellyfin","text":"<p>  [Pro Version | ryot.io]  </p> <p>Events: <code>Item marked as completed</code></p> <ol> <li>While creating the integration, you will be asked to provide your Jellyfin username and    password.</li> <li>Every time you mark a movie or show as watched in Ryot, the integration will mark it as    watched in Jellyfin.</li> </ol>"},{"location":"migration.html","title":"Migration","text":"<p>All steps below are required unless otherwise stated. Please follow them in the correct order.</p>"},{"location":"migration.html#from-v7-to-v8","title":"From <code>v7.*</code> to <code>v8.*</code>","text":"<ol> <li> <p>Upgrade the server to <code>v7.16.0</code> to make sure all <code>v7</code> migrations are applied. For    example, you can make this change: <code>image: \"ignisda/ryot:v7.16.0\"</code> in your docker-compose    file.</p> </li> <li> <p>Create a backup of your database. Here    is a guide on how to do this.</p> </li> <li> <p>Now you can upgrade to the latest version (<code>v8.*</code>). For example you can make this    change: <code>image: \"ignisda/ryot:v8\"</code> in your docker-compose file. This will    automatically apply all migrations required for the new version.</p> </li> <li> <p>OPTIONAL: Login as the admin user and go to the \"Miscellaneous\" settings page and    click on the button to \"Perform background tasks\".</p> </li> </ol>"},{"location":"migration.html#from-v6-to-v7","title":"From <code>v6.*</code> to <code>v7.*</code>","text":"<ol> <li> <p>Upgrade the server to <code>v6.11.0</code> to make sure all <code>v6</code> migrations are applied. For    example, you can make this change: <code>image: \"ignisda/ryot:v6.11.0\"</code> in your docker-compose    file.</p> </li> <li> <p>Create a backup of your database. Here    is a guide on how to do this.</p> </li> <li> <p>Now you can upgrade to the latest version (<code>v7.*</code>). For example you can make this    change: <code>image: \"ignisda/ryot:v7\"</code> in your docker-compose file. This will    automatically apply all migrations required for the new version.</p> </li> <li> <p>Login as the admin user and go to the \"Miscellaneous\" settings page and click on the    button to \"Perform background tasks\".</p> </li> </ol>"},{"location":"migration.html#from-v5-to-v6","title":"From <code>v5.*</code> to <code>v6.*</code>","text":"<p>Integrations deleted</p> <p>All integrations need to be recreated. Please take a look at the docs for the new webhook format.</p> <ol> <li> <p>Upgrade the server to <code>v5.5.6</code> to make sure all <code>v5</code> migrations are applied. For    example, you can make this change: <code>image: \"ignisda/ryot:v5.5.6\"</code> in your docker-compose    file.</p> </li> <li> <p>Create a backup of your database. Here    is a guide on how to do this.</p> </li> <li> <p>Now you can upgrade to the latest version (<code>v6.*</code>). For example you can make this    change: <code>image: \"ignisda/ryot:latest\"</code> in your docker-compose file. This will    automatically apply all migrations.</p> </li> </ol>"},{"location":"migration.html#from-v4-to-v5","title":"From <code>v4.*</code> to <code>v5.*</code>","text":"<ol> <li> <p>Upgrade the server to <code>v4.4.3</code> to make sure all <code>v4</code> migrations are applied. For    example, you can make this change: <code>image: \"ignisda/ryot:v4.4.3\"</code> in your docker-compose    file.</p> </li> <li> <p>Create a backup of your database. Here    is a guide on how to do this.</p> </li> <li> <p>Now you can upgrade to the latest version (<code>v5.*</code>). For example you can make this    change: <code>image: \"ignisda/ryot:latest\"</code> in your docker-compose file. This will    automatically apply all migrations.</p> </li> </ol>"},{"location":"migration.html#from-v3-to-v4","title":"From <code>v3.*</code> to <code>v4.*</code>","text":"<p>Webhook URL changes</p> <p>If you were using Plex, Jellyfin or Kodi, all webhooks urls will now have the <code>/backend</code> prefix. Please take a look at the integration docs for the new format.</p> <ol> <li> <p>Upgrade the server to <code>v3.5.4</code> to make sure all pending migrations are applied. For    example, you can make this change: <code>image: \"ignisda/ryot:v3.5.4\"</code> in your docker-compose    file.</p> </li> <li> <p>Go to the \"Preferences\" settings, then the \"General\" tab, and click on \"Disable yank    integrations\" twice. This will ensure that latest preferences have been applied.</p> </li> <li> <p>Go to the \"Miscellaneous\" settings and click on \"Re-evaluate workouts\".</p> </li> <li> <p>Next, click on the button to \"Clean and regenerate\" your summary. This takes time if    you have a lot of media. Go to the dashboard and check the time under the \"Summary\"    section. It should say \"Calculated just now\".</p> </li> <li> <p>Logout and then clear the local storage and cookies for your domain.    Here    is a guide on how to do this. Uninstall the PWA if you have it installed.</p> </li> <li> <p>Create a backup of the database.</p> </li> <li> <p>Connect to the database (<code>docker exec -u postgres -it ryot-db psql</code>) and run these SQL    queries:    <pre><code>DELETE FROM seaql_migrations;\n\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230410_create_metadata', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230413_create_person', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230417_create_user', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230419_create_seen', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230501_create_metadata_group', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230502_create_genre', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230504_create_collection', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230505_create_review', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230509_create_import_report', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230622_create_exercise', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230804_create_user_measurement', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230819_create_workout', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230901_create_partial_metadata', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230912_create_calendar_event', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231003_create_partial_metadata_to_person', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231016_create_collection_to_entity', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231017_create_user_to_entity', 1697640078);\n</code></pre></p> </li> <li> <p>Now you can upgrade to the latest version (<code>v4.*</code>) safely. For example you can make this    change: <code>image: \"ignisda/ryot:latest\"</code> in your docker-compose file.</p> </li> </ol>"},{"location":"migration.html#from-v2-to-v3","title":"From <code>v2.*</code> to <code>v3.*</code>","text":"<ol> <li> <p>Upgrade the server to <code>v2.24.2</code> to make sure all pending migrations are applied.</p> </li> <li> <p>Go to the \"Miscellaneous\" settings and click on the button to \"Clean and regenerate\"    your summary. This takes time if you have a lot of media. Go to the dashboard and check    the time under the \"Summary\" section. It should say \"Calculated just now\".</p> </li> <li> <p>Go to the \"Preferences\" settings, then the \"General\" tab, and click any switch button    twice to make sure the latest settings have been applied.</p> </li> <li> <p>Stop the running server and create a backup of your database.</p> </li> <li> <p>Connect to the database and run these SQL queries:    <pre><code>DELETE FROM seaql_migrations;\n\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230410_create_metadata', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230413_create_person', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230417_create_user', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230419_create_seen', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230502_create_genre', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230505_create_review', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230507_create_collection', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230509_create_import_report', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230622_create_exercise', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230804_create_user_measurement', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230819_create_workout', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230901_create_metadata_group', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230901_create_partial_metadata', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230912_create_calendar_event', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231003_create_partial_metadata_to_person', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231016_create_collection_to_entity', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231017_create_user_to_entity', 1697640078);\n</code></pre></p> </li> <li> <p>Now you can upgrade to the latest release safely.</p> </li> </ol>"},{"location":"migration.html#from-v1-to-v2","title":"From <code>v1.*</code> to <code>v2.*</code>","text":"<ol> <li> <p>Stop the running server and create a backup of your database.</p> </li> <li> <p>Run the last release of the server to perform all migrations (make sure to connect it to the correct database).    <pre><code>$ docker run --volume ./ryot/data:/data ignisda/ryot:v1.22.1\n</code></pre></p> </li> <li> <p>Once the migrations from the above step are done, stop the server.</p> </li> <li> <p>Before upgrading to the public release, connect to the database again and run these migrations:    <pre><code>DELETE FROM seaql_migrations;\n\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230410_create_metadata', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230412_create_creator', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230417_create_user', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230419_create_seen', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230502_create_genre', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230505_create_review', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230507_create_collection', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230509_create_import_report', 1684693316);\n</code></pre></p> </li> <li> <p>Now you can upgrade to the latest release safely.</p> </li> <li> <p>OPTIONAL: Once you have the new server up and running, go to the \"Miscellaneous\" settings page and click on the button to \"Update All Metadata\".</p> </li> </ol>"},{"location":"guides/authentication.html","title":"Authentication","text":"<p>Ryot supports multiple authentication methods. By default, it uses local authentication which means that you can log in using a username and password.</p>"},{"location":"guides/authentication.html#openid","title":"OpenID","text":"<p>Ryot can be configured to use OpenID Connect (OIDC) for authentication. The following environment variables need to be set:</p> <pre><code>FRONTEND_URL=https://app.ryot.io # The URL of your Ryot instance\nSERVER_OIDC_CLIENT_ID=********\nSERVER_OIDC_CLIENT_SECRET=********\nSERVER_OIDC_ISSUER_URL=https://accounts.google.com # The URL of your OIDC provider (might end with trailing slash)\n# Below are optional\nFRONTEND_OIDC_BUTTON_LABEL=Use Google\nRUST_LOG=ryot=debug # To debug why OIDC authentication is failing\n</code></pre> <p>In your OIDC provider, you will need to set the redirect URL to <code>&lt;FRONTEND_URL&gt;/api/auth</code>. The scopes required are <code>openid email</code>.</p> <p>Once these are set, restart your Ryot instance and you should be able to see the button to \"Continue with OpenID Connect\" on the authentication pages. New users will have their username set to their email address. This can be changed later in the profile settings.</p> <p>Warning</p> <p>A user can either have a username/password or it can use your OIDC provider to   authenticate but not both.</p> <p>You can set <code>USERS_DISABLE_LOCAL_AUTH=true</code> to disable local authentication and only allow users to authenticate using OIDC.</p>"},{"location":"guides/authentication.html#converting-a-local-user-to-an-oidc-user","title":"Converting a local user to an OIDC user","text":"<ul> <li>Setup OpenID on your instance using the the above guide.</li> <li>Make a backup of your database using this   guide.</li> <li>Logout of your original account and then click on \"Continue with OpenID Connect\".   Continue with user you want to select, after which a new account will be created.</li> <li>Let's say that I want <code>IgnisDa</code> below to be able to login using OIDC (of   <code>ignisda2001@gmail.com</code>): </li> <li>Drop into your database (<code>docker exec -u postgres -it ryot-db psql</code>) and copy the   <code>oidc_issuer_id</code> (<code>104798859970005336426</code> here) of the new user and then delete it using   <code>DELETE FROM \"user\" WHERE id = 'usr_v5aGOC9UzrId';</code></li> <li>Update details of the old user using   <code>UPDATE \"user\" SET oidc_issuer_id = '104798859970005336426', password = NULL WHERE id = 'usr_ujrD0pCeKc1Y';</code>.   After this, it should look like this:   </li> </ul> <p>You should now be able login using OIDC. The same procedure needs to be followed for all users that want their provider changed to OIDC.</p>"},{"location":"guides/books.html","title":"Books","text":"<p>The default provider that Ryot uses for book tracking is Openlibrary. You might find it lacking in some cases, so Ryot also supports other providers.</p>"},{"location":"guides/books.html#hardcover","title":"Hardcover","text":"<p>Ryot supports tracking books via Hardcover. I prefer this method because the quality of data is much better than Openlibrary or Google Books. As of writing this guide, the API key expires after a year, so you will need to renew it.</p> <p>You can use the following steps to obtain your own API keys:</p> <ol> <li>Create a Hardcover account.</li> <li>Go to the API Access settings page and copy the    header.</li> <li>Set the environment variable as described in the configuration    docs.    <pre><code>BOOKS_HARDCOVER_API_KEY=Bearer eyJhbGciOiJIUzI1NiIsCJ9.5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36Pw5c\n</code></pre></li> </ol>"},{"location":"guides/books.html#google-books","title":"Google Books","text":"<p>Ryot also supports tracking books via Google Books. You can follow the below steps to obtain your own API keys and enable book tracking with Google Books.</p> <ol> <li>Create a Google Cloud Platform account. Open your Google    Cloud Platform Console.</li> <li>Use the default project or click on \"Create a project\" on the dashboard.</li> <li>Open the APIs &amp; Services Dashboard.</li> <li>Click on \"Enable APIs and Services\". Search for \"Google Books API\" and click on    \"Enable\".</li> <li>Click on \"Credentials\" on the left sidebar. Click on \"Create Credentials\" and select    \"API key\".</li> <li>Click on \"Create\" and copy the API key.</li> <li>Set the <code>BOOKS_GOOGLE_BOOKS_API_KEY</code> environment variable as described in the    configuration docs.</li> </ol>"},{"location":"guides/exporting.html","title":"Exporting","text":"<p>You need to have S3 configured in order to export your data. You can find the necessary configuration parameters under the <code>FileStorageConfig</code> section. The export will be made in JSON format and always follows the schema (<code>CompleteExport</code>) described below.</p> <p>You can export your data from the app by going to the \"Imports and Exports\" settings page and then clicking the button under the \"Export\" tab. Once the export is complete, it will appear along with a button to download it.</p> <p>You can import it back using the Generic JSON Importer.</p>"},{"location":"guides/exporting.html#one-time-file-storage","title":"One time file storage","text":"<p>If you want to use file storage only for exporting, you can configure it to use a public S3 instance offered by Minio.</p> <p>Not for production use</p> <p>The Minio team resets this instance every 24 hours, hence this method is not suitable if you want to store the data for a long time.</p> <ul> <li>Go to the Minio playground. The login credentials are changed   everyday and you can find them   here.</li> <li>Click on \"Buckets\" under the \"Administrator\" section and then on \"Create Bucket\".</li> <li>Set a name and click on \"Create Bucket\".</li> <li>Click on \"Access Keys\" under the \"User\" section and then on \"Create access key\".</li> <li>Leave everything as it is and click on \"Create\". Copy both the values displayed.</li> <li>On your Ryot instance, set the following environment variables:     <pre><code>FILE_STORAGE_S3_URL=https://play.min.io\nFILE_STORAGE_S3_BUCKET_NAME=ryot-demo\nFILE_STORAGE_S3_ACCESS_KEY_ID=cqXhVseqa4mpqS4RLG3p\nFILE_STORAGE_S3_SECRET_ACCESS_KEY=sJxF4eZkuc4Eo6daGEFhTctzKzGbY6G6qAQTb8Wy\n</code></pre></li> <li>Restart your Ryot instance and follow the steps described in the previous section.</li> </ul>"},{"location":"guides/exporting.html#exporting-the-entire-database","title":"Exporting the entire database","text":"<p>While debugging, I might ask you to send me a database dump. You can do this by exporting the entire database and emailing the file.</p> <pre><code>docker exec -u postgres -i ryot-db pg_dump -Fc --no-acl --no-owner &gt; /tmp/ryot.file.sql\n</code></pre> <p>To restore the above dump, run the following command:</p> <pre><code>docker exec -u postgres -i ryot-db pg_restore -U postgres -d postgres &lt; /tmp/ryot.file.sql\n</code></pre>"},{"location":"guides/exporting.html#type-definitions","title":"Type definitions","text":"<pre><code>// Automatically generated by schematic. DO NOT MODIFY!\n\n/* eslint-disable */\n\nexport interface IdAndNamedObject {\nid: string;\nname: string;\n}\n\n/** Comments left in replies to posted reviews. */\nexport interface ImportOrExportItemReviewComment {\ncreated_on: string;\nid: string;\n/** The user ids of all those who liked it. */\nliked_by: string[];\ntext: string;\nuser: IdAndNamedObject;\n}\n\nexport type Visibility = 'public' | 'private';\n\n/** Review data associated to a rating. */\nexport interface ImportOrExportItemReview {\n/** The date the review was posted. */\ndate: string | null;\n/** Whether to mark the review as a spoiler. Defaults to false. */\nspoiler: boolean | null;\n/** Actual text for the review. */\ntext: string | null;\n/**\n     * The visibility set by the user.\n     *\n     * @default 'public'\n     */\nvisibility: Visibility | null;\n}\n\n/** A rating given to an entity. */\nexport interface ImportOrExportItemRating {\n/** If for an anime, the episode for which this review was for. */\nanime_episode_number: number | null;\n/** The comments attached to this review. */\ncomments: ImportOrExportItemReviewComment[] | null;\n/** If for a manga, the chapter for which this review was for. */\nmanga_chapter_number: string | null;\n/** If for a podcast, the episode for which this review was for. */\npodcast_episode_number: number | null;\n/** The score of the review. */\nrating: string | null;\n/** Data about the review. */\nreview: ImportOrExportItemReview | null;\n/** If for a show, the episode for which this review was for. */\nshow_episode_number: number | null;\n/** If for a show, the season for which this review was for. */\nshow_season_number: number | null;\n}\n\n/** Details about a specific exercise item that needs to be exported. */\nexport interface ImportOrExportExerciseItem {\n/** The collections this entity was added to. */\ncollections: string[];\n/** The unique identifier of the exercise. */\nid: string;\n/** The name of the exercise. */\nname: string;\n/** The review history for the user. */\nreviews: ImportOrExportItemRating[];\n}\n\n/** The actual statistics that were logged in a user measurement. */\nexport interface UserMeasurementStats {\nabdominal_skinfold: string | null;\nbasal_metabolic_rate: string | null;\nbiceps_circumference: string | null;\nbody_fat: string | null;\nbody_fat_caliper: string | null;\nbody_mass_index: string | null;\nbone_mass: string | null;\ncalories: string | null;\nchest_circumference: string | null;\nchest_skinfold: string | null;\ncustom: Record&lt;string, string&gt; | null;\nhip_circumference: string | null;\nlean_body_mass: string | null;\nmuscle: string | null;\nneck_circumference: string | null;\nthigh_circumference: string | null;\nthigh_skinfold: string | null;\ntotal_body_water: string | null;\ntotal_daily_energy_expenditure: string | null;\nvisceral_fat: string | null;\nwaist_circumference: string | null;\nwaist_to_height_ratio: string | null;\nwaist_to_hip_ratio: string | null;\nweight: string | null;\n}\n\n/** An export of a measurement taken at a point in time. */\nexport interface UserMeasurement {\n/** Any comment associated entered by the user. */\ncomment: string | null;\n/** The name given to this measurement by the user. */\nname: string | null;\n/** The contents of the actual measurement. */\nstats: UserMeasurementStats;\n/** The date and time this measurement was made. */\ntimestamp: string;\n}\n\n/** The different types of media that can be stored. */\nexport type MediaLot = 'book' | 'show' | 'movie' | 'anime' | 'manga' | 'music' | 'podcast' | 'audio_book' | 'video_game' | 'visual_novel';\n\n/** A specific instance when an entity was seen. */\nexport interface ImportOrExportMetadataItemSeen {\n/** If for an anime, the episode which was seen. */\nanime_episode_number: number | null;\n/** The timestamp when finished watching. */\nended_on: string | null;\n/** If for a manga, the chapter which was seen. */\nmanga_chapter_number: string | null;\n/** If for a manga, the volume which was seen. */\nmanga_volume_number: number | null;\n/** If for a podcast, the episode which was seen. */\npodcast_episode_number: number | null;\n/** The progress of media done. If none, it is considered as done. */\nprogress: string | null;\n/** The provider this item was watched on. */\nprovider_watched_on: string | null;\n/** If for a show, the episode which was seen. */\nshow_episode_number: number | null;\n/** If for a show, the season which was seen. */\nshow_season_number: number | null;\n/** The timestamp when started watching. */\nstarted_on: string | null;\n}\n\n/** The different sources (or providers) from which data can be obtained from. */\nexport type MediaSource = 'mal' | 'igdb' | 'tmdb' | 'vndb' | 'custom' | 'itunes' | 'anilist' | 'audible' | 'hardcover' | 'listennotes' | 'google_books' | 'openlibrary' | 'manga_updates' | 'youtube_music';\n\n/** Details about a specific media item that needs to be imported or exported. */\nexport interface ImportOrExportMetadataItem {\n/** The collections this entity was added to. */\ncollections: string[];\n/** The provider identifier. For eg: TMDB-ID, Openlibrary ID and so on. */\nidentifier: string;\n/**\n     * The type of media.\n     *\n     * @default 'book'\n     * @type {'book' | 'show' | 'movie' | 'anime' | 'manga' | 'music' | 'podcast' | 'audio_book' | 'video_game' | 'visual_novel'}\n     */\nlot: MediaLot;\n/** The review history for the user. */\nreviews: ImportOrExportItemRating[];\n/** The seen history for the user. */\nseen_history: ImportOrExportMetadataItemSeen[];\n/**\n     * The source of media.\n     *\n     * @default 'custom'\n     * @type {'mal' | 'igdb' | 'tmdb' | 'vndb' | 'custom' | 'itunes' | 'anilist' | 'audible' | 'hardcover' | 'listennotes' | 'google_books' | 'openlibrary' | 'manga_updates' | 'youtube_music'}\n     */\nsource: MediaSource;\n/** An string to help identify it in the original source. */\nsource_id: string;\n}\n\n/** Details about a specific media group item that needs to be imported or exported. */\nexport interface ImportOrExportMetadataGroupItem {\n/** The collections this entity was added to. */\ncollections: string[];\n/** The provider identifier. For eg: TMDB-ID, Openlibrary ID and so on. */\nidentifier: string;\n/**\n     * The type of media.\n     *\n     * @default 'book'\n     * @type {'book' | 'show' | 'movie' | 'anime' | 'manga' | 'music' | 'podcast' | 'audio_book' | 'video_game' | 'visual_novel'}\n     */\nlot: MediaLot;\n/** The review history for the user. */\nreviews: ImportOrExportItemRating[];\n/**\n     * The source of media.\n     *\n     * @default 'custom'\n     * @type {'mal' | 'igdb' | 'tmdb' | 'vndb' | 'custom' | 'itunes' | 'anilist' | 'audible' | 'hardcover' | 'listennotes' | 'google_books' | 'openlibrary' | 'manga_updates' | 'youtube_music'}\n     */\nsource: MediaSource;\n/** Name of the group. */\ntitle: string;\n}\n\nexport interface PersonSourceSpecifics {\nis_anilist_studio: boolean | null;\nis_hardcover_publisher: boolean | null;\nis_tmdb_company: boolean | null;\n}\n\n/** Details about a specific creator item that needs to be exported. */\nexport interface ImportOrExportPersonItem {\n/** The collections this entity was added to. */\ncollections: string[];\n/** The provider identifier. */\nidentifier: string;\n/** The name of the creator. */\nname: string;\n/** The review history for the user. */\nreviews: ImportOrExportItemRating[];\n/**\n     * The source of data.\n     *\n     * @default 'custom'\n     * @type {'mal' | 'igdb' | 'tmdb' | 'vndb' | 'custom' | 'itunes' | 'anilist' | 'audible' | 'hardcover' | 'listennotes' | 'google_books' | 'openlibrary' | 'manga_updates' | 'youtube_music'}\n     */\nsource: MediaSource;\n/** The source specific data. */\nsource_specifics: PersonSourceSpecifics | null;\n}\n\n/** The assets that were uploaded for an entity. */\nexport interface EntityAssets {\n/** The keys of the S3 images. */\nimages: string[];\n/** The keys of the S3 videos. */\nvideos: string[];\n}\n\n/** Information about a workout done. */\nexport interface WorkoutDuration {\nfrom: string;\nto: string | null;\n}\n\n/** The different types of exercises that can be done. */\nexport type ExerciseLot = 'reps' | 'duration' | 'reps_and_weight' | 'reps_and_duration' | 'distance_and_duration' | 'reps_and_duration_and_distance';\n\n/** The types of set (mostly characterized by exertion level). */\nexport type SetLot = 'normal' | 'warm_up' | 'drop' | 'failure';\n\n/** The different types of personal bests that can be achieved on a set. */\nexport type WorkoutSetPersonalBest = 'time' | 'pace' | 'reps' | 'one_rm' | 'volume' | 'weight' | 'distance';\n\n/** Details about the statistics of the set performed. */\nexport interface WorkoutSetStatistic {\ndistance: string | null;\nduration: string | null;\none_rm: string | null;\npace: string | null;\nreps: string | null;\nvolume: string | null;\nweight: string | null;\n}\n\nexport interface WorkoutSetTotals {\nweight: string | null;\n}\n\n/** Details about the set performed. */\nexport interface WorkoutSetRecord {\nconfirmed_at: string | null;\n/**\n     * @default 'normal'\n     * @type {'normal' | 'warm_up' | 'drop' | 'failure'}\n     */\nlot: SetLot;\nnote: string | null;\npersonal_bests: WorkoutSetPersonalBest[] | null;\nrest_time: number | null;\nrest_timer_started_at: string | null;\nrpe: number | null;\nstatistic: WorkoutSetStatistic;\ntotals: WorkoutSetTotals | null;\n}\n\n/** The totals of a workout and the different bests achieved. */\nexport interface WorkoutOrExerciseTotals {\ndistance: string;\nduration: string;\n/** The number of personal bests achieved. */\npersonal_bests_achieved: number;\nreps: string;\n/** The total seconds that were logged in the rest timer. */\nrest_time?: number;\nweight: string;\n}\n\n/** An exercise that has been processed and committed to the database. */\nexport interface ProcessedExercise {\nassets: EntityAssets | null;\nid: string;\n/**\n     * @default 'reps_and_weight'\n     * @type {'reps' | 'duration' | 'reps_and_weight' | 'reps_and_duration' | 'distance_and_duration' | 'reps_and_duration_and_distance'}\n     */\nlot: ExerciseLot;\nnotes: string[];\nsets: WorkoutSetRecord[];\ntotal: WorkoutOrExerciseTotals | null;\n}\n\nexport interface WorkoutSupersetsInformation {\n/** A color that will be displayed on the frontend. */\ncolor: string;\n/** The identifier of all the exercises which are in the same superset */\nexercises: number[];\n}\n\n/** Information about a workout done. */\nexport interface WorkoutInformation {\nassets: EntityAssets | null;\ncomment: string | null;\ndurations: WorkoutDuration[] | null;\nexercises: ProcessedExercise[];\nsupersets: WorkoutSupersetsInformation[];\n}\n\n/** The summary about an exercise done in a workout. */\nexport interface WorkoutSummaryExercise {\nbest_set: WorkoutSetRecord | null;\nid: string;\n/** @default 'reps_and_weight' */\nlot: ExerciseLot | null;\nnum_sets: number;\n}\n\nexport type ExerciseEquipment = 'bands' | 'cable' | 'other' | 'barbell' | 'machine' | 'body_only' | 'dumbbell' | 'foam_roll' | 'ez_curl_bar' | 'kettlebells' | 'exercise_ball' | 'medicine_ball';\n\nexport interface WorkoutEquipmentFocusedSummary {\n/**\n     * @default 'barbell'\n     * @type {'bands' | 'cable' | 'other' | 'barbell' | 'machine' | 'body_only' | 'dumbbell' | 'foam_roll' | 'ez_curl_bar' | 'kettlebells' | 'exercise_ball' | 'medicine_ball'}\n     */\nequipment: ExerciseEquipment;\nexercises: number[];\n}\n\nexport type ExerciseForce = 'pull' | 'push' | 'static';\n\nexport interface WorkoutForceFocusedSummary {\nexercises: number[];\n/**\n     * @default 'pull'\n     * @type {'pull' | 'push' | 'static'}\n     */\nforce: ExerciseForce;\n}\n\nexport type ExerciseLevel = 'beginner' | 'expert' | 'intermediate';\n\nexport interface WorkoutLevelFocusedSummary {\nexercises: number[];\n/**\n     * @default 'beginner'\n     * @type {'beginner' | 'expert' | 'intermediate'}\n     */\nlevel: ExerciseLevel;\n}\n\nexport interface WorkoutLotFocusedSummary {\nexercises: number[];\n/**\n     * @default 'reps_and_weight'\n     * @type {'reps' | 'duration' | 'reps_and_weight' | 'reps_and_duration' | 'distance_and_duration' | 'reps_and_duration_and_distance'}\n     */\nlot: ExerciseLot;\n}\n\nexport type ExerciseMuscle = 'lats' | 'neck' | 'traps' | 'chest' | 'biceps' | 'calves' | 'glutes' | 'triceps' | 'forearms' | 'abductors' | 'adductors' | 'lower_back' | 'shoulders' | 'abdominals' | 'hamstrings' | 'middle_back' | 'quadriceps';\n\nexport interface WorkoutMuscleFocusedSummary {\nexercises: number[];\n/**\n     * @default 'abdominals'\n     * @type {'lats' | 'neck' | 'traps' | 'chest' | 'biceps' | 'calves' | 'glutes' | 'triceps' | 'forearms' | 'abductors' | 'adductors' | 'lower_back' | 'shoulders' | 'abdominals' | 'hamstrings' | 'middle_back' | 'quadriceps'}\n     */\nmuscle: ExerciseMuscle;\n}\n\nexport interface WorkoutFocusedSummary {\nequipments: WorkoutEquipmentFocusedSummary[];\nforces: WorkoutForceFocusedSummary[];\nlevels: WorkoutLevelFocusedSummary[];\nlots: WorkoutLotFocusedSummary[];\nmuscles: WorkoutMuscleFocusedSummary[];\n}\n\nexport interface WorkoutSummary {\nexercises: WorkoutSummaryExercise[];\nfocused: WorkoutFocusedSummary;\ntotal: WorkoutOrExerciseTotals | null;\n}\n\nexport interface WorkoutTemplate {\ncreated_on: string;\nid: string;\ninformation: WorkoutInformation;\nname: string;\nsummary: WorkoutSummary;\n}\n\nexport interface ImportOrExportWorkoutTemplateItem {\ncollections: string[];\ndetails: WorkoutTemplate;\n}\n\n/** A workout that was completed by the user. */\nexport interface Workout {\ncalories_burnt: string | null;\nduration: number;\nend_time: string;\nid: string;\ninformation: WorkoutInformation;\nname: string;\nstart_time: string;\nsummary: WorkoutSummary;\ntemplate_id: string | null;\n}\n\n/** Details about a specific exercise item that needs to be exported. */\nexport interface ImportOrExportWorkoutItem {\n/** The collections this entity was added to. */\ncollections: string[];\n/** The details of the workout. */\ndetails: Workout;\n}\n\n/** Complete export of the user. */\nexport interface CompleteExport {\n/** Data about user's exercises. */\nexercises: ImportOrExportExerciseItem[] | null;\n/** Data about user's measurements. */\nmeasurements: UserMeasurement[] | null;\n/** Data about user's media. */\nmetadata: ImportOrExportMetadataItem[] | null;\n/** Data about user's media groups. */\nmetadata_groups: ImportOrExportMetadataGroupItem[] | null;\n/** Data about user's people. */\npeople: ImportOrExportPersonItem[] | null;\n/** Data about user's workout templates. */\nworkout_templates: ImportOrExportWorkoutTemplateItem[] | null;\n/** Data about user's workouts. */\nworkouts: ImportOrExportWorkoutItem[] | null;\n}\n</code></pre>"},{"location":"guides/video-games.html","title":"Video games","text":"<p>A guide about video games integration for Ryot.</p>"},{"location":"guides/video-games.html#integration-with-igdb","title":"Integration with IGDB","text":"<p>Ryot supports tracking video games via IGDB. However, the API is heavily rate limited, so it is not possible to hardcode the API keys in the application (unlike the others).</p> <p>You can follow the below steps to obtain your own API keys and enable video game tracking.</p>"},{"location":"guides/video-games.html#steps","title":"Steps","text":"<ol> <li>Create a Twitch account.</li> <li>Open your developer console.</li> <li>Click on \"Register Your Application\" on the dashboard.</li> <li>Fill up the details. Any name will suffice but it must be unique. Click on \"Create\"    when you are done.</li> <li>You will be guided back to your application dashboard. Click on \"Manage\" for    the application you just created.</li> <li>Generate a client secret. Copy the Client ID and Client Secret.</li> <li>Set the <code>VIDEO_GAMES_*</code> environment variables as described in the    configuration docs.</li> </ol>"}]}